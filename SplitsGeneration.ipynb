{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path :/work/aprimpel/datasets_for_notebooks/datasetProfilingtrain_test_val/magellan_datasets/bikes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate,cross_val_predict, StratifiedShuffleSplit\n",
    "from datautils import*\n",
    "import os\n",
    "import os.path as path\n",
    "from profiling import *\n",
    "from learningutils import *\n",
    "from sklearn import tree\n",
    "import json\n",
    "from matching_task import *\n",
    "import datetime\n",
    "\n",
    "sep_for_source_files= ','\n",
    "gs_sep = ','\n",
    "main_path='../datasets/'\n",
    "source_folder ='magellan_datasets'\n",
    "\n",
    "\n",
    "for r, d, f in os.walk(main_path+source_folder+'/'):\n",
    "    print(\"Current path :\"+r)\n",
    "    \n",
    "    if r!=main_path+source_folder+'/':\n",
    "        dataset_name = r.split(\"/\")[-1]\n",
    "\n",
    "    else: continue\n",
    "    ds1=pd.DataFrame()\n",
    "    ds2=pd.DataFrame()\n",
    "    gs=pd.DataFrame()\n",
    "    for file in f:\n",
    "\n",
    "        feature_vector_train,feature_vector_test,feature_vector_validation = None, None,  None\n",
    "\n",
    "        if '.csv' in file and 'standard_2' in file:\n",
    "            gs = pd.read_csv(r+'/'+file, sep=gs_sep)\n",
    "        if path.exists(r+\"/feature_vector_train.csv\"):\n",
    "            feature_vector_train = pd.read_csv(r+\"/feature_vector_train.csv\", sep =\",\", engine='python')\n",
    "        if path.exists(r+\"/feature_vector_test.csv\"):\n",
    "            feature_vector_test = pd.read_csv(r+\"/feature_vector_test.csv\", sep =\",\", engine='python')\n",
    "        if path.exists(r+\"/feature_vector_validation.csv\"):\n",
    "            feature_vector_validation = pd.read_csv(r+\"/feature_vector_validation.csv\", sep =\",\", engine='python')\n",
    "        if '.csv' in file and 'standard' not in file and 'feature' not in file:\n",
    "            if '1_' in file : ds1= pd.read_csv(r+'/'+file, sep =sep_for_source_files, engine='python')\n",
    "            if '2_' in file:  ds2= pd.read_csv(r+'/'+file, sep =sep_for_source_files, engine='python')\n",
    "\n",
    "        if not ds1.empty and not ds2.empty and not gs.empty: break    \n",
    "\n",
    "\n",
    "    if not ds1.empty and not ds2.empty and not gs.empty and feature_vector_train is None and feature_vector_test is None and feature_vector_validation is None:\n",
    "        ds1['subject_id'] = ds1['subject_id'].apply(str)\n",
    "        ds2['subject_id'] = ds2['subject_id'].apply(str)\n",
    "\n",
    "        if (source_folder==\"leipzig_datasets\" or source_folder==\"corleone_datasets\"):\n",
    "            ds1['subject_id'] = ds1['subject_id'].str.lower()\n",
    "            ds2['subject_id'] = ds2['subject_id'].str.lower()\n",
    "\n",
    "\n",
    "        gs['source_id'] = gs['source_id'].apply(str)\n",
    "        gs['target_id'] = gs['target_id'].apply(str)\n",
    "\n",
    "        if path.exists(r+\"/feature_vector.csv\"):\n",
    "            feature_vector = pd.read_csv(r+\"/feature_vector.csv\", sep =\",\", engine='python')\n",
    "        else: \n",
    "            feature_vector = createFeatureVectorFile(ds1,ds2,gs, embeddings = False, printProgress=True, saveFile=r+\"/feature_vector.csv\")\n",
    "\n",
    "        X = feature_vector\n",
    "        y = feature_vector['label'].values\n",
    "        sssplits_train_test = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=1)\n",
    "        train_index, val_test_index = next(sssplits_train_test.split(X,y))\n",
    "        X_train, X_val_test, y_train, y_val_test = X.loc[train_index], X.loc[val_test_index],y[train_index],y[val_test_index]\n",
    "        X_val_test.reset_index(inplace=True)\n",
    "        X_train.reset_index(inplace=True)   \n",
    "        sssplits_val_test = StratifiedShuffleSplit(n_splits=1, test_size=0.33, random_state=1)\n",
    "        val_index, test_index = next(sssplits_val_test.split(X_val_test, y_val_test))\n",
    "        X_val, X_test, y_val, y_test = X_val_test.loc[val_index], X_val_test.loc[test_index], y_val_test[val_index], y_val_test[test_index]\n",
    "        X_val.drop(columns=['index'], inplace=True)\n",
    "        X_test.drop(columns=['index'], inplace=True)\n",
    "        X_train.drop(columns=['index'], inplace=True)\n",
    "        X_val.to_csv(r+\"/feature_vector_validation.csv\", index=False)\n",
    "        X_test.to_csv(r+\"/feature_vector_test.csv\", index=False)\n",
    "        X_train.to_csv(r+\"/feature_vector_train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
